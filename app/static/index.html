<!-- app/static/index.html -->
<!DOCTYPE html>
<html>
<head>
    <title>Voice Agent</title>
    <style>
        body { font-family: sans-serif; text-align: center; margin-top: 50px; }
        #status { font-weight: bold; color: gray; }
        button { padding: 15px 30px; font-size: 18px; cursor: pointer; }
    </style>
</head>
<body>
    <h1>ğŸ™ï¸ Barge-In Voice Agent</h1>
    <p id="status">Disconnected</p>
    <button id="startBtn">Start Conversation</button>

    <script>
        const startBtn = document.getElementById('startBtn');
        const status = document.getElementById('status');
        let ws;
        let audioContext;
        let processor;
        let inputStream;

        let audioQueue = [];
        let isPlaying = false;

        startBtn.onclick = async () => {
            status.innerText = "Connecting...";
            audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
            await audioContext.resume();

            ws = new WebSocket(`ws://${location.host}/ws/voice`);
            ws.binaryType = 'arraybuffer';

            ws.onopen = () => {
                status.innerText = "ğŸŸ¢ Online - Speak now!";
                startBtn.disabled = true;
                initMicrophone();
            };

            ws.onmessage = async (event) => {
                enqueueAudio(event.data);
            };
            
            ws.onclose = () => {
                status.innerText = "ğŸ”´ Disconnected";
                startBtn.disabled = false;
                stopAudio();
            };
        };

        async function initMicrophone() {
            const stream = await navigator.mediaDevices.getUserMedia({ 
                audio: { 
                    channelCount: 1, 
                    sampleRate: 16000,
                    echoCancellation: true,
                    noiseSuppression: true
                } 
            });
            inputStream = stream;
            const source = audioContext.createMediaStreamSource(stream);
            processor = audioContext.createScriptProcessor(4096, 1, 1);

            processor.onaudioprocess = (e) => {
                if (ws && ws.readyState === WebSocket.OPEN) {
                    // Send microphone data to server
                    ws.send(e.inputBuffer.getChannelData(0));
                }
            };

            source.connect(processor);
            processor.connect(audioContext.destination);
        }

        function enqueueAudio(arrayBuffer) {
            audioQueue.push(arrayBuffer);
            if (!isPlaying) {
                playNextChunk();
            }
        }

        function playNextChunk() {
            if (audioQueue.length === 0) {
                isPlaying = false;
                return;
            }

            isPlaying = true;
            const audioData = audioQueue.shift();

            audioContext.decodeAudioData(audioData, (buffer) => {
                const source = audioContext.createBufferSource();
                source.buffer = buffer;
                source.connect(audioContext.destination);
                
                source.onended = () => {
                    playNextChunk();
                };
                
                source.start(0);
            }, (e) => console.error("Error decoding audio:", e));
        }

        function stopAudio() {
            if (processor) processor.disconnect();
            if (inputStream) inputStream.getTracks().forEach(track => track.stop());
        }
    </script>
</body>
</html>